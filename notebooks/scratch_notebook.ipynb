{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b4badf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "from sqlalchemy import text\n",
    "import duckdb\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "load_dotenv()\n",
    "DATABASE_URL = f\"postgresql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/{os.getenv('DB_NAME')}\"\n",
    "engine = create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "117453ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine \n",
    "start_year=2024 \n",
    "end_year=2024 \n",
    "parquet_folder = 'data/raw/nflfastr/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "dd0fc76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_df = pd.read_sql(\"SELECT * FROM weekly_stats\", engine)\n",
    "players_df = pd.read_sql(\"SELECT * FROM players\", engine)\n",
    "teams_df = pd.read_sql('SELECT * FROM teams', engine)\n",
    "games_df = pd.read_sql('SELECT * FROM games', engine)\n",
    "depth_df = pd.read_sql('SELECT * FROM depth_chart', engine)\n",
    "injuries_df = pd.read_sql('SELECT * FROM injuries', engine)\n",
    "schedule_df = pd.read_sql(\"SELECT season, week, stadium, game_date FROM games\", engine)\n",
    "base_features_df = pd.read_sql(\"SELECT * FROM player_weekly_features\", engine)\n",
    "pre_features_df = pd.read_sql(\"SELECT * FROM player_weekly_features\", engine)\n",
    "final_df = pd.read_sql(\"SELECT * FROM features\", engine)\n",
    "qb_df = pd.read_sql(\"SELECT * FROM qb_features\", engine)\n",
    "rb_df = pd.read_sql(\"SELECT * FROM rb_features\", engine)\n",
    "wr_df = pd.read_sql(\"SELECT * FROM wr_features\", engine)\n",
    "te_df = pd.read_sql(\"SELECT * FROM te_features\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "00c044b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import joblib\n",
    "import argparse\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from datetime import datetime\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "de282c76",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[253]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m TARGET = \u001b[33m\"\u001b[39m\u001b[33mfantasy_points\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m EXCLUDE_COLS = [\u001b[33m\"\u001b[39m\u001b[33mplayer_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mplayer_name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mseason\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mweek\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mplayer_display_name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mposition\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mteam_abbreviation\u001b[39m\u001b[33m\"\u001b[39m, TARGET]\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m BASE_DIR = os.path.dirname(os.path.abspath(\u001b[34;43m__file__\u001b[39;49m))\n\u001b[32m      8\u001b[39m MODEL_DIR = os.path.join(BASE_DIR, \u001b[33m\"\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m LOG_DIR = os.path.join(BASE_DIR, \u001b[33m\"\u001b[39m\u001b[33mmodel_logs\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "POSITION = 'qb'\n",
    "MODEL_DIR = \"models\"\n",
    "TABLE_NAME = f\"{POSITION}_features\"\n",
    "TARGET = \"fantasy_points\"\n",
    "EXCLUDE_COLS = [\"player_id\", \"player_name\", \"season\", \"week\", \"player_display_name\", \"position\", \"team_abbreviation\", TARGET]\n",
    "\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "MODEL_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "LOG_DIR = os.path.join(BASE_DIR, \"model_logs\")\n",
    "# ------------------------\n",
    "# FUNCTIONS\n",
    "# ------------------------\n",
    "def load_data():\n",
    "    load_dotenv()\n",
    "    DATABASE_URL = f\"postgresql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/{os.getenv('DB_NAME')}\"\n",
    "    engine = create_engine(DATABASE_URL)\n",
    "\n",
    "    df = pd.read_sql(f\"SELECT * FROM {TABLE_NAME}\", engine)\n",
    "    return df\n",
    "\n",
    "\n",
    "def train_test_split_for_week(df, season, week):\n",
    "    \"\"\"\n",
    "    Simulate predicting for a specific season/week by holding out that week as test.\n",
    "    All prior weeks are used for training.\n",
    "    \"\"\"\n",
    "    train_df = df[(df[\"season\"] < season) | ((df[\"season\"] == season) & (df[\"week\"] < week))]\n",
    "    test_df = df[(df[\"season\"] == season) & (df[\"week\"] == week)]\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def get_features(df, train_df, test_df):\n",
    "    \"\"\"Select feature columns dynamically and handle categorical/bool types automatically.\"\"\"\n",
    "    features = [col for col in df.columns if col not in EXCLUDE_COLS]\n",
    "\n",
    "    # Detect categorical columns (object or category types)\n",
    "    cat_cols = train_df.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "    for col in cat_cols:\n",
    "        train_df[col] = train_df[col].astype(\"category\")\n",
    "        test_df[col] = test_df[col].astype(\"category\")\n",
    "\n",
    "    # Detect boolean-like columns (0/1 or True/False)\n",
    "    bool_cols = [col for col in train_df.columns \n",
    "                 if train_df[col].dropna().nunique() == 2 and \n",
    "                 sorted(train_df[col].dropna().unique()) in [[0, 1], [False, True], ['false','true']]]\n",
    "    for col in bool_cols:\n",
    "        train_df[col] = train_df[col].astype(bool)\n",
    "        test_df[col] = test_df[col].astype(bool)\n",
    "\n",
    "    train_df['dome'] = train_df['dome'].astype(bool)\n",
    "    test_df['dome'] = test_df['dome'].astype(bool)\n",
    "\n",
    "    X_train = train_df[features]\n",
    "    y_train = train_df[TARGET]\n",
    "\n",
    "    X_test = test_df[features]\n",
    "    y_test = test_df[TARGET]\n",
    "\n",
    "    return features, X_train, y_train, X_test, y_test\n",
    "\n",
    "def train_model(train_df, features):\n",
    "    \"\"\"Train an XGBoost regression model.\"\"\"\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        enable_categorical=True\n",
    "    )\n",
    "    model.fit(train_df[features], train_df[TARGET])\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, season, week,\n",
    "                   position=POSITION, model_name=None, log_dir=LOG_DIR):\n",
    "    if model_name is None:\n",
    "        model_name = f\"{position}_model_{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "    print(\"Evaluating model performance...\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    metrics = {\n",
    "        \"season\": season,\n",
    "        \"week\": week,\n",
    "        \"position\": position,\n",
    "        \"rmse_train\": np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
    "        \"mae_train\": mean_absolute_error(y_train, y_pred_train),\n",
    "        \"r2_train\": r2_score(y_train, y_pred_train),\n",
    "        \"rmse_test\": np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "        \"mae_test\": mean_absolute_error(y_test, y_pred_test),\n",
    "        \"r2_test\": r2_score(y_test, y_pred_test),\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y%m%d%H%M%S\"),\n",
    "        \"model_name\": model_name\n",
    "    }\n",
    "\n",
    "    print(\"\\nModel Evaluation Metrics:\")\n",
    "    for k, v in metrics.items():\n",
    "        if isinstance(v, float):\n",
    "            print(f\"{k}: {v:.4f}\")\n",
    "        else:\n",
    "            print(f\"{k}: {v}\")\n",
    "\n",
    "    # Logging path\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    csv_path = os.path.join(log_dir, \"metrics_log.csv\")\n",
    "\n",
    "    if os.path.exists(csv_path):\n",
    "        df_log = pd.read_csv(csv_path)\n",
    "    else:\n",
    "        df_log = pd.DataFrame()\n",
    "\n",
    "    # Find best previous model for this season/week/position by test MAE\n",
    "    best_mae = df_log.loc[\n",
    "        (df_log['season'] == season) &\n",
    "        (df_log['week'] == week) &\n",
    "        (df_log['position'] == position),\n",
    "        'mae_test'\n",
    "    ].min() if not df_log.empty else np.inf\n",
    "\n",
    "    if metrics['mae_test'] < best_mae:\n",
    "        print(f\"New model outperforms existing best MAE ({best_mae:.4f}). Will save model.\")\n",
    "        save_flag = True\n",
    "    else:\n",
    "        print(f\"Model did NOT outperform existing best MAE ({best_mae:.4f}). Model will NOT be saved.\")\n",
    "        save_flag = False\n",
    "\n",
    "    # Append new metrics anyway\n",
    "    df_log = pd.concat([df_log, pd.DataFrame([metrics])], ignore_index=True)\n",
    "    df_log.to_csv(csv_path, index=False)\n",
    "    print(f\"Metrics appended to {csv_path}\")\n",
    "\n",
    "    return metrics, save_flag\n",
    "\n",
    "\n",
    "def save_model(model, filename = f\"qb_model_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.pkl\"):\n",
    "    \"\"\"Save model to disk.\"\"\"\n",
    "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "    path = os.path.join(MODEL_DIR, filename)\n",
    "    joblib.dump(model, path)\n",
    "    print(f\"Model saved to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc2725f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Evaluation Metrics:\n",
      "rmse_train: 0.1099\n",
      "mae_train: 0.0776\n",
      "r2_train: 0.9998\n",
      "rmse_test: 2.7148\n",
      "mae_test: 1.9712\n",
      "r2_test: 0.8896\n",
      "timestamp: 2025-08-08 00:13:43\n",
      "model_name: qb_model_2025-08-07 23:41:23\n",
      "Metrics appended to model_logs/metrics_log.csv\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[252]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m features, X_train, y_train, X_test, y_test = get_features(df, train_df, test_df)\n\u001b[32m      4\u001b[39m model = train_model(train_df, features)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m metrics, save_flag = evaluate_model(model, X_train, y_train, X_test, y_test)\n\u001b[32m      6\u001b[39m save_model(model)\n",
      "\u001b[31mValueError\u001b[39m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "df = load_data()\n",
    "train_df, test_df = train_test_split_for_week(df, season=2024, week=8)\n",
    "features, X_train, y_train, X_test, y_test = get_features(df, train_df, test_df)\n",
    "model = train_model(train_df, features)\n",
    "metrics, save_flag = evaluate_model(model, X_train, y_train, X_test, y_test)\n",
    "save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "1ca72d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Evaluation Metrics:\n",
      "rmse_train: 0.1549\n",
      "mae_train: 0.1099\n",
      "r2_train: 0.9997\n",
      "rmse_test: 2.4957\n",
      "mae_test: 1.7383\n",
      "r2_test: 0.9067\n",
      "timestamp: 2025-08-07 23:31:30\n",
      "model_name: qb_model_2025-08-07 23:31:26\n",
      "Metrics appended to modeling/model_logs/metrics_log.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rmse_train': np.float64(0.15489133389522242),\n",
       " 'mae_train': 0.10993546221180071,\n",
       " 'r2_train': 0.9997002206054424,\n",
       " 'rmse_test': np.float64(2.4956915882256125),\n",
       " 'mae_test': 1.7383012952449475,\n",
       " 'r2_test': 0.9066947024917293,\n",
       " 'timestamp': '2025-08-07 23:31:30',\n",
       " 'model_name': 'qb_model_2025-08-07 23:31:26'}"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "5024b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../src/modeling/model_logs/metrics_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "73c59ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>week</th>\n",
       "      <th>position</th>\n",
       "      <th>rmse_train</th>\n",
       "      <th>mae_train</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>rmse_test</th>\n",
       "      <th>mae_test</th>\n",
       "      <th>r2_test</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>qb</td>\n",
       "      <td>0.138277</td>\n",
       "      <td>0.099496</td>\n",
       "      <td>0.999763</td>\n",
       "      <td>1.953717</td>\n",
       "      <td>1.550636</td>\n",
       "      <td>0.927511</td>\n",
       "      <td>20250808162936</td>\n",
       "      <td>qb_model_season2024_week16_20250808162936.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.152360</td>\n",
       "      <td>0.083271</td>\n",
       "      <td>0.999283</td>\n",
       "      <td>0.379498</td>\n",
       "      <td>0.208738</td>\n",
       "      <td>0.995105</td>\n",
       "      <td>20250808162939</td>\n",
       "      <td>wr_model_season2024_week16_20250808162939.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.119383</td>\n",
       "      <td>0.077948</td>\n",
       "      <td>0.999703</td>\n",
       "      <td>1.227154</td>\n",
       "      <td>0.613614</td>\n",
       "      <td>0.977920</td>\n",
       "      <td>20250808162942</td>\n",
       "      <td>rb_model_season2024_week16_20250808162942.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.052052</td>\n",
       "      <td>0.034624</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.405181</td>\n",
       "      <td>0.205259</td>\n",
       "      <td>0.985529</td>\n",
       "      <td>20250808162944</td>\n",
       "      <td>te_model_season2024_week16_20250808162944.pkl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  week position  rmse_train  mae_train  r2_train  rmse_test  \\\n",
       "0  2024.0  16.0       qb    0.138277   0.099496  0.999763   1.953717   \n",
       "1     NaN   NaN      NaN    0.152360   0.083271  0.999283   0.379498   \n",
       "2     NaN   NaN      NaN    0.119383   0.077948  0.999703   1.227154   \n",
       "3     NaN   NaN      NaN    0.052052   0.034624  0.999852   0.405181   \n",
       "\n",
       "   mae_test   r2_test       timestamp  \\\n",
       "0  1.550636  0.927511  20250808162936   \n",
       "1  0.208738  0.995105  20250808162939   \n",
       "2  0.613614  0.977920  20250808162942   \n",
       "3  0.205259  0.985529  20250808162944   \n",
       "\n",
       "                                      model_name  \n",
       "0  qb_model_season2024_week16_20250808162936.pkl  \n",
       "1  wr_model_season2024_week16_20250808162939.pkl  \n",
       "2  rb_model_season2024_week16_20250808162942.pkl  \n",
       "3  te_model_season2024_week16_20250808162944.pkl  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "61f3fa71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20250807234827'"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e101a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
