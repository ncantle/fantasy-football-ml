{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7daf268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "DATABASE_URL = f\"postgresql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/{os.getenv('DB_NAME')}\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# Example 32 teams (abbreviations)\n",
    "teams = ['ARI', 'ATL', 'BAL', 'BUF', 'CAR', 'CHI', 'CIN', 'CLE', 'DAL', 'DEN', 'DET', 'GB', \n",
    "         'HOU', 'IND', 'JAX', 'KC', 'LV', 'LAC', 'LAR', 'MIA', 'MIN', 'NE', 'NO', 'NYG', \n",
    "         'NYJ', 'PHI', 'PIT', 'SEA', 'SF', 'TB', 'TEN', 'WAS']\n",
    "\n",
    "# Randomly generate pairings for 18 weeks\n",
    "weeks = list(range(1, 19))\n",
    "schedule = []\n",
    "\n",
    "# Just for mock purposes: each team plays a different one at home each week\n",
    "for week in weeks:\n",
    "    for i, home_team in enumerate(teams[:16]):  # Limit to 16 matchups\n",
    "        away_team = teams[(i + week) % 32]  # Rotate for variation\n",
    "        schedule.append({\n",
    "            'season': 2024,\n",
    "            'week': week,\n",
    "            'home_team': home_team,\n",
    "            'away_team': away_team\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(schedule)\n",
    "\n",
    "df = df.merge(teams_df, how='left', left_on='home_team', right_on='abbreviation')\n",
    "df.rename(columns = {'team_id':'home_team_id'}, inplace=True)\n",
    "df.drop(columns = ['abbreviation'], inplace = True)\n",
    "\n",
    "df = df.merge(teams_df, how = 'left', left_on = 'away_team', right_on = 'abbreviation')\n",
    "df.rename(columns = {'team_id':'away_team_id'}, inplace=True)\n",
    "df.drop(columns = ['abbreviation'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "18753684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Weekly stats successfully ingested into PostgreSQL.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load credentials\n",
    "load_dotenv()\n",
    "DATABASE_URL = f\"postgresql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/{os.getenv('DB_NAME')}\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# Load NFLFastR player weekly stats parquet file\n",
    "df = pd.read_parquet(\"data/raw/nflfastr/player_stats_2023.parquet\")\n",
    "\n",
    "# Prepare weekly stats dataframe\n",
    "weekly_stats_df = df.rename(columns={\n",
    "    'season': 'season',\n",
    "    'week': 'week',\n",
    "    'player_id': 'player_id',\n",
    "    'recent_team': 'team_abbreviation',\n",
    "    'targets': 'targets',\n",
    "    'carries': 'carries',\n",
    "    'offense_snaps': 'snaps'\n",
    "})\n",
    "\n",
    "# Link team_id from teams table\n",
    "teams_df = pd.read_sql('SELECT team_id, abbreviation FROM teams', engine)\n",
    "weekly_stats_df = weekly_stats_df.merge(teams_df, how='left', left_on='team_abbreviation', right_on='abbreviation')\n",
    "\n",
    "# Final columns for ingestion\n",
    "weekly_stats_df = weekly_stats_df[['season', 'week', 'player_id', 'team_id', 'fantasy_points', 'targets', 'carries']]\n",
    "\n",
    "# Drop rows where player_id or team_id is missing (data integrity)\n",
    "weekly_stats_df = weekly_stats_df.dropna(subset=['player_id', 'team_id'])\n",
    "\n",
    "# Ensure types match schema\n",
    "weekly_stats_df['player_id'] = weekly_stats_df['player_id'].str.replace(r'[^a-zA-Z0-9]', '', regex=True)\n",
    "weekly_stats_df['player_id'] = weekly_stats_df['player_id'].astype(int)\n",
    "weekly_stats_df['team_id'] = weekly_stats_df['team_id'].astype(int)\n",
    "\n",
    "# Ingest into PostgreSQL\n",
    "weekly_stats_df.to_sql('weekly_stats', engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"✅ Weekly stats successfully ingested into PostgreSQL.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8b2f39cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data/raw/nflfastr/player_stats_2023.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "91cf31e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['player_id', 'player_name', 'player_display_name', 'position',\n",
       "       'position_group', 'headshot_url', 'recent_team', 'season', 'week',\n",
       "       'season_type', 'opponent_team', 'completions', 'attempts',\n",
       "       'passing_yards', 'passing_tds', 'interceptions', 'sacks', 'sack_yards',\n",
       "       'sack_fumbles', 'sack_fumbles_lost', 'passing_air_yards',\n",
       "       'passing_yards_after_catch', 'passing_first_downs', 'passing_epa',\n",
       "       'passing_2pt_conversions', 'pacr', 'dakota', 'carries', 'rushing_yards',\n",
       "       'rushing_tds', 'rushing_fumbles', 'rushing_fumbles_lost',\n",
       "       'rushing_first_downs', 'rushing_epa', 'rushing_2pt_conversions',\n",
       "       'receptions', 'targets', 'receiving_yards', 'receiving_tds',\n",
       "       'receiving_fumbles', 'receiving_fumbles_lost', 'receiving_air_yards',\n",
       "       'receiving_yards_after_catch', 'receiving_first_downs', 'receiving_epa',\n",
       "       'receiving_2pt_conversions', 'racr', 'target_share', 'air_yards_share',\n",
       "       'wopr', 'special_teams_tds', 'fantasy_points', 'fantasy_points_ppr'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cddc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL Query to assemble player-week stats\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    ws.season,\n",
    "    ws.week,\n",
    "    p.player_id,\n",
    "    p.name,\n",
    "    t.abbreviation AS team,\n",
    "    p.team_id,\n",
    "    p.position,\n",
    "    CASE \n",
    "        WHEN p.team_id = g.home_team_id THEN g.away_team\n",
    "        ELSE g.home_team\n",
    "    END AS opponent,\n",
    "    ws.fantasy_points,\n",
    "    ws.targets,\n",
    "    ws.carries,\n",
    "    d.depth_position,\n",
    "    i.injury_status\n",
    "FROM weekly_stats ws\n",
    "LEFT JOIN players p ON ws.player_id = p.player_id\n",
    "LEFT JOIN teams t ON p.team_id = t.team_id\n",
    "LEFT JOIN games g ON ws.season = g.season AND ws.week = g.week\n",
    "LEFT JOIN depth_chart d ON p.player_id = d.player_id\n",
    "LEFT JOIN injuries i \n",
    "    ON p.player_id = i.player_id \n",
    "    AND ws.week = i.week \n",
    "    AND ws.season = i.season\n",
    "ORDER BY ws.season, ws.week, p.name;\n",
    "\"\"\"\n",
    "\n",
    "# Execute query and export\n",
    "df = pd.read_sql(query, engine).drop_duplicates()\n",
    "df.to_csv(\"data/processed/player_weekly_stats.csv\", index=False)\n",
    "\n",
    "print(\"✅ Exported to data/processed/player_weekly_stats.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
